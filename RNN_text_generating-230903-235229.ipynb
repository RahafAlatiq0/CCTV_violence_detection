{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN for Text Generation"
      ],
      "metadata": {
        "id": "ldWNT8Rw_D7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import libraries"
      ],
      "metadata": {
        "id": "MWcpIbFcNeQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "0XMzJAU0DDRB"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare the sample text"
      ],
      "metadata": {
        "id": "EhlJ3NHDNiR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input text\n",
        "input_text = \"RNN-based text generation techniques have a wide range of applications, from creative writing to chatbots, and they rely on understanding the inherent sequential nature of text data to produce meaningful and human-like language.\"\n"
      ],
      "metadata": {
        "id": "MMmYxOHeCzi9"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this code is to provide a sample input text that can be used in a very simple text generation task\n"
      ],
      "metadata": {
        "id": "qN51TTCmN0jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(input_text)))"
      ],
      "metadata": {
        "id": "Az34MYDtCzgD"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGM6wpGZOOcD",
        "outputId": "617efdd3-a0f7-4901-9691-7b87fdd161f8"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " 'N',\n",
              " 'R',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This variable is used to create a sorted list of unique characters (individual letters, symbols, and whitespace) from the input_text variable"
      ],
      "metadata": {
        "id": "H-vqbjudOFny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = {char: index for index, char in enumerate(chars)}\n",
        "index_to_char = {index: char for index, char in enumerate(chars)}"
      ],
      "metadata": {
        "id": "HSZ8PMnWDBW6"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will create two dictionaries: char_to_index and index_to_char. These dictionaries are used for mapping characters to their corresponding indices and vice versa"
      ],
      "metadata": {
        "id": "WxpNYy3mOW8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 20\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []"
      ],
      "metadata": {
        "id": "UhWtp2zIDBUC"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the data for the training. The maximum length of a swquence is 20 characters.\n",
        "\n",
        "The step size determines the stride when creating overlapping input sequences. A step of 3 means that the input sequences will overlap by 3 characters\n",
        "\n",
        "Lastly, we created two empty lists that will be used to store the sentences and the target characters."
      ],
      "metadata": {
        "id": "rk8ZCf9BPK3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(input_text) - maxlen, step):\n",
        "    sentences.append(input_text[i:i+maxlen])\n",
        "    next_chars.append(input_text[i+maxlen])"
      ],
      "metadata": {
        "id": "9sUZoTmlDBRN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we want to extract the overlapping sequences of characters from the input_text and create pairs of input sequences and their corresponding target characters. These pairs serve as the training dataset for training an RNN-based text generation model."
      ],
      "metadata": {
        "id": "ddhlovZ7P8eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)"
      ],
      "metadata": {
        "id": "OB4yVI99DBOj"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Two NumPy arrays, x and y, are created to facilitate one-hot encoding for the input and target data in text generation training."
      ],
      "metadata": {
        "id": "z9ALJbHSQNhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "xLNnp_nJE-LV"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " A nested loop structure is used to populate the x and y NumPy arrays with one-hot encoded representations of characters from input sequences (sentences) and target characters (next_chars). The outer loop iterates through input sequences, while the inner loop processes individual characters within each sequence."
      ],
      "metadata": {
        "id": "nqXd0Zw1Q4q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN Model"
      ],
      "metadata": {
        "id": "88xlm6JaQZYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    SimpleRNN(128, input_shape=(maxlen, len(chars))),\n",
        "    Dense(len(chars), activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "YFf_91lvFBV1"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the recurrent layer with 128 units (neurons). It processes sequences of characters and captures sequential patterns. We are using a dense layer with equal number of neurons as the unique characters in our vocabulary.\n",
        "\n",
        "The activation function used is softmax"
      ],
      "metadata": {
        "id": "fuGuUSRzRV1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write this line of code to do the following:\n",
        "  # Compile the model\n",
        "  # Use categorical crossentropy as the loss function\n",
        "  # Use adam as an optimizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "-q97UybYFCaf"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1, verbose=2)\n",
        "    start_index = np.random.randint(0, len(input_text) - maxlen)\n",
        "    generated_text = input_text[start_index:start_index + maxlen]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CyiOWJDFDm_",
        "outputId": "17bb66dc-b391-407a-952c-8d3d96dceb69"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 2s - loss: 3.4486 - 2s/epoch - 2s/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 3.2875 - 18ms/epoch - 18ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 3.1325 - 18ms/epoch - 18ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 2.9831 - 29ms/epoch - 29ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 2.8404 - 17ms/epoch - 17ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 2.7052 - 19ms/epoch - 19ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 2.5771 - 18ms/epoch - 18ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 2.4529 - 18ms/epoch - 18ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 2.3306 - 24ms/epoch - 24ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 2.2111 - 11ms/epoch - 11ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 2.0961 - 12ms/epoch - 12ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 1.9843 - 11ms/epoch - 11ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 1.8734 - 12ms/epoch - 12ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 1.7626 - 11ms/epoch - 11ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 1.6530 - 12ms/epoch - 12ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 1.5464 - 12ms/epoch - 12ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 1.4437 - 14ms/epoch - 14ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 1.3455 - 12ms/epoch - 12ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 1.2534 - 11ms/epoch - 11ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 1.1680 - 12ms/epoch - 12ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 1.0869 - 11ms/epoch - 11ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 1.0074 - 11ms/epoch - 11ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.9299 - 11ms/epoch - 11ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.8565 - 14ms/epoch - 14ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.7875 - 17ms/epoch - 17ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.7228 - 11ms/epoch - 11ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.6624 - 11ms/epoch - 11ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.6056 - 12ms/epoch - 12ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.5517 - 12ms/epoch - 12ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.5017 - 11ms/epoch - 11ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.4560 - 13ms/epoch - 13ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.4140 - 12ms/epoch - 12ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.3754 - 12ms/epoch - 12ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.3401 - 11ms/epoch - 11ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.3079 - 11ms/epoch - 11ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.2789 - 12ms/epoch - 12ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.2529 - 19ms/epoch - 19ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.2296 - 14ms/epoch - 14ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.2086 - 12ms/epoch - 12ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.1896 - 12ms/epoch - 12ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.1724 - 11ms/epoch - 11ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.1570 - 11ms/epoch - 11ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.1435 - 11ms/epoch - 11ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.1315 - 11ms/epoch - 11ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.1208 - 21ms/epoch - 21ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.1111 - 15ms/epoch - 15ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.1025 - 11ms/epoch - 11ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.0947 - 11ms/epoch - 11ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.0877 - 11ms/epoch - 11ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.0814 - 11ms/epoch - 11ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.0758 - 10ms/epoch - 10ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.0707 - 11ms/epoch - 11ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.0661 - 11ms/epoch - 11ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.0620 - 16ms/epoch - 16ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.0583 - 11ms/epoch - 11ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.0549 - 11ms/epoch - 11ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.0518 - 11ms/epoch - 11ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.0490 - 11ms/epoch - 11ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.0464 - 11ms/epoch - 11ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.0441 - 17ms/epoch - 17ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.0419 - 11ms/epoch - 11ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.0400 - 11ms/epoch - 11ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.0382 - 12ms/epoch - 12ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.0365 - 12ms/epoch - 12ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.0350 - 18ms/epoch - 18ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.0336 - 11ms/epoch - 11ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.0322 - 11ms/epoch - 11ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.0310 - 11ms/epoch - 11ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.0299 - 11ms/epoch - 11ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.0288 - 11ms/epoch - 11ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.0278 - 11ms/epoch - 11ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.0269 - 28ms/epoch - 28ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.0261 - 12ms/epoch - 12ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.0253 - 12ms/epoch - 12ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.0245 - 12ms/epoch - 12ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.0238 - 11ms/epoch - 11ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.0231 - 11ms/epoch - 11ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.0225 - 11ms/epoch - 11ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.0219 - 25ms/epoch - 25ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.0213 - 11ms/epoch - 11ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.0207 - 12ms/epoch - 12ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.0202 - 11ms/epoch - 11ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.0197 - 11ms/epoch - 11ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.0193 - 11ms/epoch - 11ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.0188 - 11ms/epoch - 11ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.0184 - 15ms/epoch - 15ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.0180 - 11ms/epoch - 11ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.0176 - 12ms/epoch - 12ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.0173 - 11ms/epoch - 11ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.0169 - 12ms/epoch - 12ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.0166 - 12ms/epoch - 12ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.0162 - 11ms/epoch - 11ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.0159 - 29ms/epoch - 29ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.0156 - 12ms/epoch - 12ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.0153 - 14ms/epoch - 14ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.0151 - 12ms/epoch - 12ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.0148 - 12ms/epoch - 12ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.0145 - 12ms/epoch - 12ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.0143 - 11ms/epoch - 11ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.0140 - 12ms/epoch - 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    for _ in range(200):\n",
        "        sampled = np.zeros((1, maxlen, len(chars)), dtype=bool)\n",
        "        for t, char in enumerate(generated_text):\n",
        "            sampled[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        preds = model.predict(sampled, verbose=0)[0]\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = index_to_char[next_index]\n",
        "\n",
        "        generated_text += next_char\n",
        "        generated_text = generated_text[1:]\n",
        "\n",
        "    print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq31am3XFGCT",
        "outputId": "f35f2ac1-34d9-436f-94f8-403acab55d9d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " eneeee   ttheiattni\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise:\n",
        "**1. Explain the generated results?** why did the model generate this?\n",
        "\n",
        "\n",
        "**2. Modify the input text:** For this example, we've used a very small input text, use the following text file and observe the model behavior.\n",
        "https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt"
      ],
      "metadata": {
        "id": "SrrmDGLYG8aB"
      }
    }
  ]
}