{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import packages"
      ],
      "metadata": {
        "id": "XcJd9UzG3I9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "\n",
        "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
        "#from official.projects.movinet.modeling import w\n",
        "#from official.projects.movinet.modeling import movinet_model"
      ],
      "metadata": {
        "id": "SIumpR5NAsB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from pathlib import Path\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "import collections\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "kaggle_username = \"rahaf8\"\n",
        "kaggle_key = \"f59b8cb26f2973bc6fb4c52b1516ac19\"\n",
        "os.environ[\"KAGGLE_USERNAME\"] = kaggle_username\n",
        "os.environ[\"KAGGLE_KEY\"] = kaggle_key\n",
        "import kaggle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "crpJ0COcY2Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Functions"
      ],
      "metadata": {
        "id": "n4geNZG43RTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Get data from Kaggle"
      ],
      "metadata": {
        "id": "eEMfdN8E3X6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_kaggle_dataset(dataset_name):\n",
        "    \"\"\"Get dataset from Kaggle.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: the dataset name.\n",
        "    \"\"\"\n",
        "\n",
        "    # Download the dataset using the Kaggle API\n",
        "    kaggle.api.dataset_download_files(dataset_name, path=\".\", unzip=True)"
      ],
      "metadata": {
        "id": "Te69JLXQ2lh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Video Dataframe Generator"
      ],
      "metadata": {
        "id": "tk1wraTG3qtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_dataframe(data_dir):\n",
        "  \"\"\"Get video dataframe.\n",
        "\n",
        "    Args:\n",
        "      files_path: A path from which the files can be stored.\n",
        "\n",
        "    Returns:\n",
        "      Video dataframe containing the labels , videos name , and videos path.\n",
        "  \"\"\"\n",
        "  vidDf = pd.DataFrame(columns=['Label','VidName','VidPath'])\n",
        "\n",
        "  for dirname, _, filenames in os.walk(data_dir):\n",
        "      for name in filenames:\n",
        "            vidDf =  vidDf.append({'Label': re.match(r'^[^\\d_]+', name).group(),\n",
        "                                   'VidName': name,\n",
        "                                   'VidPath': os.path.join(dirname, name)},\n",
        "                                    ignore_index=True)\n",
        "  return vidDf"
      ],
      "metadata": {
        "id": "rLTPe1bJL6Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Split Dataset"
      ],
      "metadata": {
        "id": "pVe-7dpk4e1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SplitData(testsize, df, classes):\n",
        "    min_samples_per_class = min(df.groupby(\"Label\").size())\n",
        "    print(f\"{min_samples_per_class} Samples per Class\")\n",
        "\n",
        "    df_TrainingSet = pd.DataFrame(columns=df.columns)\n",
        "    df_TestSet = pd.DataFrame(columns=df.columns)\n",
        "\n",
        "    for class_label in classes:\n",
        "        df_class = df[df['Label'] == class_label].sample(min_samples_per_class, random_state=42)\n",
        "\n",
        "        training_set, test_set = train_test_split(df_class, test_size=testsize, random_state=42)\n",
        "\n",
        "        df_TrainingSet = df_TrainingSet.append(training_set)\n",
        "        df_TestSet = df_TestSet.append(test_set)\n",
        "\n",
        "    df_TrainingSet = df_TrainingSet.sample(frac=1, random_state=42)\n",
        "    df_TestSet = df_TestSet.sample(frac=1, random_state=42)\n",
        "\n",
        "    return df_TrainingSet, df_TestSet"
      ],
      "metadata": {
        "id": "YuHIZ_YSCDSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Move video into train and test"
      ],
      "metadata": {
        "id": "Gl3vRNSX8r0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def delete_empty_folders(directory):\n",
        "    for root, dirs, files in os.walk(directory, topdown=False):\n",
        "        for dir_name in dirs:\n",
        "            folder_path = os.path.join(root, dir_name)\n",
        "            delete_empty_folders(folder_path)  # Recursively check subdirectories\n",
        "        if not os.listdir(root) and not files:\n",
        "            os.rmdir(root)\n",
        "\n",
        "def move_videos_to_folders(df, destination_dir):\n",
        "    for _, row in df.iterrows():\n",
        "        label = row['Label']\n",
        "        vid_name = row['VidName']\n",
        "        vid_path = row['VidPath']\n",
        "\n",
        "        folder_path = os.path.join(destination_dir, label)\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "        new_vid_path = os.path.join(folder_path, vid_name)\n",
        "        shutil.move(vid_path, new_vid_path)\n",
        "\n",
        "        df.loc[df['VidPath'] == vid_path, 'VidPath'] = new_vid_path"
      ],
      "metadata": {
        "id": "hy_dbj0W5Ogp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 This code has been copied from tensorflow website without any changes - task for tomorrow"
      ],
      "metadata": {
        "id": "l2TYEqbV9cGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  return frame\n",
        "\n",
        "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "  need_length = 1 + (n_frames - 1) * frame_step\n",
        "\n",
        "  if need_length > video_length:\n",
        "    start = 0\n",
        "  else:\n",
        "    max_start = video_length - need_length\n",
        "    start = random.randint(0, max_start + 1)\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "  ret, frame = src.read()\n",
        "  result.append(format_frames(frame, output_size))\n",
        "\n",
        "  for _ in range(n_frames - 1):\n",
        "    for _ in range(frame_step):\n",
        "      ret, frame = src.read()\n",
        "    if ret:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      result.append(np.zeros_like(result[0]))\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result\n",
        "\n",
        "class FrameGenerator:\n",
        "  def __init__(self, path, n_frames, training = False):\n",
        "    \"\"\" Returns a set of frames with their associated label.\n",
        "\n",
        "      Args:\n",
        "        path: Video file paths.\n",
        "        n_frames: Number of frames.\n",
        "        training: Boolean to determine if training dataset is being created.\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.n_frames = n_frames\n",
        "    self.training = training\n",
        "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
        "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "  def get_files_and_class_names(self):\n",
        "    video_paths = list(self.path.glob('*/*.mp4'))\n",
        "    classes = [p.parent.name for p in video_paths]\n",
        "    return video_paths, classes\n",
        "\n",
        "  def __call__(self):\n",
        "    video_paths, classes = self.get_files_and_class_names()\n",
        "\n",
        "    pairs = list(zip(video_paths, classes))\n",
        "\n",
        "    if self.training:\n",
        "      random.shuffle(pairs)\n",
        "\n",
        "    for path, name in pairs:\n",
        "      video_frames = frames_from_video_file(path, self.n_frames)\n",
        "      label = self.class_ids_for_name[name] # Encode labels\n",
        "      yield video_frames, label"
      ],
      "metadata": {
        "id": "egA392-Z9RYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing"
      ],
      "metadata": {
        "id": "ssxWAkKp4O-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"shashiprakash204/ucfcrimeminidataset\"\n",
        "dataset_dir = \"/content/dataset/\"\n",
        "\n",
        "get_kaggle_dataset(dataset_name)"
      ],
      "metadata": {
        "id": "VsdinTHK4R9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_df = video_dataframe(dataset_dir)\n",
        "classes = video_df['Label'].unique().tolist()\n",
        "print('Number of classes', len(classes))\n",
        "print('Num videos for each class: : ')\n",
        "print(video_df['Label'].value_counts())"
      ],
      "metadata": {
        "id": "x6e8i--rehke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = SplitData(0.2, video_df,classes)"
      ],
      "metadata": {
        "id": "9xwLcswetdIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddata = {\"Training\":train_df.groupby(\"Label\").size(),\"Test\":test_df.groupby(\"Label\").size()}\n",
        "\n",
        "ddataframe = pd.DataFrame(data=ddata)\n",
        "ddataframe.plot.bar(stacked= True, rot= 15, title='Training vs Test data',figsize=(15,5))\n",
        "plt.show(block= True)"
      ],
      "metadata": {
        "id": "YVVxLD9721gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_destination_dir = '/content/dataset/train'\n",
        "test_destination_dir = '/content/dataset/test'\n",
        "\n",
        "# Move videos to train folders\n",
        "move_videos_to_folders(train_df, train_destination_dir)\n",
        "\n",
        "# Move videos to test folders\n",
        "move_videos_to_folders(test_df, test_destination_dir)\n",
        "\n",
        "#delete empty folders\n",
        "delete_empty_folders('/content/dataset')"
      ],
      "metadata": {
        "id": "NfbOa2X_6KXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "num_frames = 8\n",
        "\n",
        "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(Path(train_destination_dir), num_frames, training = True),\n",
        "                                          output_signature = output_signature)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(Path(test_destination_dir), num_frames),\n",
        "                                         output_signature = output_signature)\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "vsWJhNY1292p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frames, labels in train_ds.take(10):\n",
        "  print(labels)"
      ],
      "metadata": {
        "id": "8Mo7GDl8-uBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape: {frames.shape}\")\n",
        "print(f\"Label: {labels.shape}\")"
      ],
      "metadata": {
        "id": "59LH2qwD-3lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## the code below is copied from tensorflow website without any changes - task for tomorrow"
      ],
      "metadata": {
        "id": "bIUEHjiFB6hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru = layers.GRU(units=4, return_sequences=True, return_state=True)\n",
        "\n",
        "inputs = tf.random.normal(shape=[1, 10, 8]) # (batch, sequence, channels)\n",
        "\n",
        "result, state = gru(inputs) # Run it all at once"
      ],
      "metadata": {
        "id": "QgrjZq6P-5RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_half, state = gru(inputs[:, :5, :])   # run the first half, and capture the state\n",
        "second_half, _ = gru(inputs[:,5:, :], initial_state=state)  # Use the state to continue where you left off.\n",
        "\n",
        "print(np.allclose(result[:, :5,:], first_half))\n",
        "print(np.allclose(result[:, 5:,:], second_half))"
      ],
      "metadata": {
        "id": "chs2sbD7B7Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'a0'\n",
        "resolution = 224\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "backbone = movinet.Movinet(model_id=model_id)\n",
        "backbone.trainable = False\n",
        "\n",
        "# Set num_classes=600 to load the pre-trained weights from the original model\n",
        "model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
        "model.build([None, None, None, None, 3])\n",
        "\n",
        "# Load pre-trained weights\n",
        "!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n",
        "!tar -xvf movinet_a0_base.tar.gz\n",
        "\n",
        "checkpoint_dir = f'movinet_{model_id}_base'\n",
        "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "status = checkpoint.restore(checkpoint_path)\n",
        "status.assert_existing_objects_matched()"
      ],
      "metadata": {
        "id": "D7VoRSxHB-2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
        "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone=backbone,\n",
        "      num_classes=num_classes)\n",
        "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "oJ4GS9QTCA4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_classifier(batch_size, num_frames, resolution, backbone, 10)"
      ],
      "metadata": {
        "id": "4QGjks51CCIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IC2TAm69CDoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_ds,\n",
        "                    validation_data=test_ds,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_freq=1,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "1-WlgpvoCFVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ],
      "metadata": {
        "id": "W3BlNoCICIme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actual_predicted_labels(dataset):\n",
        "  \"\"\"\n",
        "    Create a list of actual ground truth values and the predictions from the model.\n",
        "\n",
        "    Args:\n",
        "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
        "\n",
        "    Return:\n",
        "      Ground truth and predicted values for a particular dataset.\n",
        "  \"\"\"\n",
        "  actual = [labels for _, labels in dataset.unbatch()]\n",
        "  predicted = model.predict(dataset)\n",
        "\n",
        "  actual = tf.stack(actual, axis=0)\n",
        "  predicted = tf.concat(predicted, axis=0)\n",
        "  predicted = tf.argmax(predicted, axis=1)\n",
        "\n",
        "  return actual, predicted"
      ],
      "metadata": {
        "id": "k3RE_h_wCLfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
        "  cm = tf.math.confusion_matrix(actual, predicted)\n",
        "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
        "  sns.set(rc={'figure.figsize':(12, 12)})\n",
        "  sns.set(font_scale=1.4)\n",
        "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
        "  ax.set_xlabel('Predicted Action')\n",
        "  ax.set_ylabel('Actual Action')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "eqzk3JWmKG4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fg = FrameGenerator(Path(train_destination_dir), num_frames, training = True)\n",
        "label_names = list(fg.class_ids_for_name.keys())"
      ],
      "metadata": {
        "id": "4f2al16ECQi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = get_actual_predicted_labels(test_ds)"
      ],
      "metadata": {
        "id": "B1l5S1kVCR7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'MobileNet Model accuracy on the test set is : {accuracy_score(actual, predicted )*100:.2f}%')"
      ],
      "metadata": {
        "id": "pFh8oMy7LlCV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}